# -*- coding: utf-8 -*-
"""WikiQA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BPgqE7KGj9Hu5PladCDX4G82ES-puWRv

# Note to developers
Search for TODO tags to see what more can be done, if time permits.

# Research Paper
Read the paper here: https://arxiv.org/pdf/1704.00051.pdf

#Setup Notebook
"""

from google.colab import drive
import os

drive.mount('/gdrive', force_remount = True)
os.chdir('/gdrive/My Drive/NLP Project/')

import numpy as np
import pandas as pd

import spacy
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from keras.preprocessing.text import Tokenizer
from gensim.models.word2vec import Word2Vec
import gensim.downloader as api

import pickle
import json
import string
import collections

"""#Datasets

###Wikipedia
This dataset contains summaries of Wikipedia articles. A summary or introduction of an article is everything starting from the page title up to the content outline. See: https://github.com/tscheepers/Wikipedia-Summary-Dataset
"""

ARTICLES = 100000     # No. of articles for dataframe

# uncomment to download
'''os.chdir('wikipedia')
!wget http://blob.thijs.ai/wiki-summary-dataset/without-stop-words.tar.gz
!tar -xzf without-stop-words.tar.gz
os.chdir('..')'''

wiki = pd.read_csv('wikipedia/without-stop-words.txt', 
                   sep=" \|\|\| ", 
                   header=None, 
                   nrows=ARTICLES, 
                   error_bad_lines=False)

wiki.columns = ["Title", "Text"]
wiki.dropna(inplace=True)
wiki.reset_index(inplace=True, drop=True)
wiki.head()

"""###SQuAD
Reference for JSON to DataFrame conversion: https://www.kaggle.com/sanjay11100/squad-stanford-q-a-json-to-pandas-dataframe
"""

#!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json

def squad_json_to_dataframe_train(input_file_path, 
                                  record_path = ['data','paragraphs','qas','answers'],
                                  verbose = 1):
    """
    input_file_path: path to the squad json file.
    record_path: path to deepest level in json file default value is
    ['data','paragraphs','qas','answers']
    verbose: 0 to suppress it default is 1
    """
    if verbose:
        print("Reading the json file")    
    file = json.loads(open(input_file_path).read())
    if verbose:
        print("processing...")
    # parsing different level's in the json file
    js = pd.io.json.json_normalize(file , record_path )
    m = pd.io.json.json_normalize(file, record_path[:-1] )
    r = pd.io.json.json_normalize(file,record_path[:-2])
    
    #combining it into single dataframe
    idx = np.repeat(r['context'].values, r.qas.str.len())
    ndx  = np.repeat(m['id'].values,m['answers'].str.len())
    m['context'] = idx
    js['q_idx'] = ndx
    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()
    main['c_id'] = main['context'].factorize()[0]
    if verbose:
        print("shape of the dataframe is {}".format(main.shape))
        print("Done")
    return main

squad = squad_json_to_dataframe_train('train-v2.0.json')
squad.head()

"""#Document Retriever

### Inverted Index
Reference: http://www.dalkescientific.com/writings/diary/archive/2011/12/23/inverted_index.html
"""

inverted_index = collections.defaultdict(set)
for index, row in wiki.iterrows():
    for word in row['Text'].split():
        inverted_index[word].add((index, row['Title']))

sample_words = ['book', 'science', 'coffee', 'novel', 'internet']
documents = []
for word in sample_words:
    articles = []
    for i, article in enumerate(inverted_index[word]):
        articles.append(article[1])
        if i == 4:
            break
    documents.append(articles)

documents

df = pd.DataFrame(list(zip(sample_words, documents)), columns=['word', 'articles'])
df

for item in inverted_index['anarchism']:
    print(item)

"""### DocumentRetriever Class
Methods
+ find(q = 'Question here?'): Returns a list of titles of articles which are relevant for the question.
"""

class DocumentRetriever:
    def __init__(self):
        return

    # pass question as q
    def find(self, q='What is anarchism?', count=5):
        # split into words
        q = q.lower().translate(str.maketrans('', '', string.punctuation)).split()

        # inverted-index lookup
        titles = []
        for q_word in q:
            titles.extend(inverted_index[q_word])
        titles = list(set(titles))

        # prepare corpus of articles found in inverted-index lookup
        question = ' '.join(q)
        corpus = [question]
        for (index, title) in titles:
            text = wiki.iloc[index, 0].upper() + ' | ' + wiki.iloc[index, 1]
            corpus.append(str(text))

        # TF-IDF on articles found in inverted-index lookup
        tfidf = TfidfVectorizer()
        vecs = tfidf.fit_transform(corpus)
        corr_matrix = ((vecs * vecs.T).A)
        result = [corpus[i] for i in np.argsort(corr_matrix[0])[::-1][:count+1]]

        return result[1:]

ret = DocumentRetriever()
ret.find(q='mozart', count=10)

"""# Document Reader

### Components

Tokenizer
"""

'''
Notes
-----
+ tokenizer.fit_on_texts(train_data)
+ texts_to_sequences(paragraph_to_tokenize)
+ word_index: dictionary to convert indices to words
'''
tokenizer = Tokenizer()
tokenizer.fit_on_texts(wiki['Text'])

"""Lemmatizer: https://www.machinelearningplus.com/nlp/lemmatization-examples-python/"""

# Initialize spacy 'en' model, which can be used for lemmatization
nlp = spacy.load('en')

"""Word embeddings: https://github.com/kavgan/nlp-in-practice/blob/master/pre-trained-embeddings/Pre-trained%20embeddings.ipynb"""

#glove = api.load("glove-wiki-gigaword-300")
#outfile = open('glove','wb')
#pickle.dump(glove, outfile)
#outfile.close()

'''
Notes
-----
+ glove['word']
+ glove.most_similar('word')
'''
infile = open('glove','rb')
glove = pickle.load(infile)
infile.close()

"""Exact match features"""

#TODO: Use un-lowercased corpus
def exact_match(paragraph, question):
    q = question.translate(str.maketrans('', '', string.punctuation))
    exact_matches = []
    for word in paragraph:
        match = {}
        match['original'] = True if word in q.split() else False
        match['lowercase'] = True if word in q.lower().split() else False
        match['stem'] = True if nlp(word)[0].lemma_ in [word.lemma_ for word in nlp(q)] else False
        exact_matches.append(match)
    return exact_matches

"""Token features"""

def token_features(doc, counts):
    token_features = []
    for token in doc:
        token_feat = {}
        token_feat['POS'] = token.pos_   # POS
        token_feat['NER'] = True if token.ent_iob_ in ['I', 'B'] else False  # NER
        token_feat['TF'] = counts[token] / sum(counts.values())  # Normalized TF
        token_features.append(token_feat)
    return token_features

"""Putting it all together: Paragraph features"""

def paragraph_features(paragraph, question):
    doc = nlp(paragraph)
    counts = collections.Counter(doc)
    f_emb, f_exact_match, f_token, f_align = [], [], [], []
    
    f_emb.append(glove[str(token)] for token in doc)
    f_exact_match = exact_match(paragraph, question)
    f_token = token_features(doc, counts)
    f_align = []  # TODO: f_align

    return f_emb, f_exact_match, f_token, f_align

paragraph_features(wiki['Text'][0], 'What is anarchism?')

"""### Paragraph encoding
Feature vector for a token
+ word embeddings
+ exact match
+ token features
+ aligned question embedding

Encoding
+ code = RNN(feature vectors)
"""

def encode_paragraph(paragraph):
    # tokenize the paragraph
    tokens = tokenizer.texts_to_sequences(paragraph)

    # get word embeddings for the tokens

class DocumentReader:
    def __init__(self):
        return

    def

{'batchcomplete': '', 'continue': {'sroffset': 10, 'continue': '-||'}, 'query': {'searchinfo': {'totalhits': 3358}, 'search': [{'ns': 0, 'title': 'Anarchist schools of thought', 'pageid': 46399274, 'size': 112018, 'wordcount': 12600, 'snippet': '<span class="searchmatch">Anarchism</span> <span class="searchmatch">is</span> the <span class="searchmatch">political</span> <span class="searchmatch">philosophy</span> which holds ruling classes and the state to be undesirable, unnecessary and harmful, or alternatively as opposing', 'timestamp': '2020-11-14T19:12:16Z'}, {'ns': 0, 'title': 'Anarchism', 'pageid': 12, 'size': 98307, 'wordcount': 10851, 'snippet': '<span class="searchmatch">Anarchism</span> <span class="searchmatch">is</span> <span class="searchmatch">a</span> <span class="searchmatch">political</span> <span class="searchmatch">philosophy</span> and movement that <span class="searchmatch">is</span> sceptical of authority and rejects all involuntary, coercive forms of hierarchy. <span class="searchmatch">Anarchism</span> calls', 'timestamp': '2020-11-28T13:16:29Z'}, {'ns': 0, 'title': 'Outline of anarchism', 'pageid': 14946461, 'size': 67351, 'wordcount': 7205, 'snippet': 'The following outline <span class="searchmatch">is</span> provided as an overview of and topical guide to <span class="searchmatch">anarchism</span>, generally defined as the <span class="searchmatch">political</span> <span class="searchmatch">philosophy</span> which holds the state', 'timestamp': '2020-10-14T05:44:18Z'}, {'ns': 0, 'title': 'Issues in anarchism', 'pageid': 5773736, 'size': 168250, 'wordcount': 19677, 'snippet': '<span class="searchmatch">Anarchism</span> <span class="searchmatch">is</span> generally defined as the <span class="searchmatch">political</span> <span class="searchmatch">philosophy</span> which holds the state to be undesirable, unnecessary and harmful as well as opposing authority', 'timestamp': '2020-11-07T01:23:01Z'}, {'ns': 0, 'title': 'Libertarian anarchism', 'pageid': 16102540, 'size': 1920, 'wordcount': 239, 'snippet': 'Libertarian <span class="searchmatch">anarchism</span> may refer to: <span class="searchmatch">Anarchism</span>, <span class="searchmatch">a</span> <span class="searchmatch">political</span> <span class="searchmatch">philosophy</span> that advocates stateless societies, usually considered <span class="searchmatch">a</span> radical far left ideology', 'timestamp': '2020-10-08T16:03:21Z'}, {'ns': 0, 'title': 'National-anarchism', 'pageid': 2307316, 'size': 46052, 'wordcount': 5440, 'snippet': 'nationalism with philosophical <span class="searchmatch">anarchism</span>, mainly in their support for <span class="searchmatch">a</span> stateless society whilst rejecting anarchist social <span class="searchmatch">philosophy</span>. The main ideological innovation', 'timestamp': '2020-11-15T17:19:56Z'}, {'ns': 0, 'title': 'Egoist anarchism', 'pageid': 20264216, 'size': 53303, 'wordcount': 6053, 'snippet': '<span class="searchmatch">anarchism</span> or anarcho-egoism, often shortened as simply egoism, <span class="searchmatch">is</span> <span class="searchmatch">a</span> school of anarchist thought that originated in the <span class="searchmatch">philosophy</span> of Max Stirner, <span class="searchmatch">a</span> 19th-century', 'timestamp': '2020-11-23T01:01:49Z'}, {'ns': 0, 'ti
